Root cause analysis

With a CrashLoopBackOff eror, Kubernetes will wait an increasing back-off time between restarts to allow time for the issue to be resolved. As such, CrashLoopBackOff is not an error on itself, but indicates that thereâ€™s an error happening that prevents a Pod from starting properly. It keeps trying the deployment (hence the CrashLoopBackOff) in case the conmf

This is saying that the config map has not been created within the kubernetes namespace within which myapp-deployment is running. This is preventing the pod from deploying correctly.

It's possible its been misnamed and is running

kubectl get configmap

will show what config maps exist or not.

If it's not a typo, then the configmap will need to be created. I don't know the exact data that will be needed, but the yaml could look something like this. 

apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-config
data:
  config.yaml: |
    server:
      port: 8080
    database:
      host: db.mycompany.internal
      port: 1521
      user: myappuser
      password: secretpassword

The configmap can be deployed indepentantly (a short term fix) using 

kubectl apply -f myapp-config.yaml

A more long term solution would be to ideally create the configmap prior to the application deployment. Alternatively, it can be added at the top of the existing yaml, exspecially if the config is only required by this application; It's added to the  existing yaml, seperated from the next deploment defination by ---

...
      port: 1521
      user: myappuser
      password: secretpassword
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  ...

The config.yaml is the file name that will be created inside the container. The full path will be /etc/myapp/config.yaml base on the CONFIG_PATH value.

There is also a second error within the YAML. It's missing the selector field in the spec section of the Deployment. The selector is required and must match the pod template's labels.

The complete yaml will look like this

apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-config
data:
  config.yaml: |
    server:
      port: 8080
    database:
      host: db.mycompany.internal
      port: 1521
      user: myappuser
      password: secretpassword
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  labels:
    app: myapp
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
        - name: myapp-container
          image: myregistry/myapp:2.0.1
          ports:
            - containerPort: 5000
          env:
            - name: CONFIG_PATH
              value: "/etc/myapp/config.yaml"
          volumeMounts:
            - name: config-volume
              mountPath: "/etc/myapp/"
              readOnly: true
      volumes:
        - name: config-volume
          configMap:
            name: myapp-config

To confirm if either solution resolves the issue, you can check using 

kubectl get pods 

and the status should be 'Ready'

kubectl get configmap

to confirm the config map is created correctly

kubectel describe pod 

will also show if there are any warnings, but will also show if the mount has completed and the application deployed. 